{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46796d72-1883-45b1-a270-97dfe23572bc",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "8e4fd80d-6be3-43d8-bde7-ac4579871e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import mediapipe as mp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mediapipe.framework.formats import detection_pb2\n",
    "from mediapipe.framework.formats import location_data_pb2\n",
    "from mediapipe.framework.formats import landmark_pb2\n",
    "\n",
    "from mediapipe.python.solutions.pose import PoseLandmark\n",
    "from mediapipe.python.solutions.drawing_utils import DrawingSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "0ef6c50f-b2f4-4eb7-afca-d60d69159427",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1459962f-8b02-4fd1-b530-fd9eacc16cef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "596c5c9f-6626-49ab-949f-4878fc378ef1",
   "metadata": {},
   "source": [
    "## Process Own Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "8a3a937b-11ad-4b99-a2fc-a3a9e0416d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_style = mp_drawing_styles.get_default_pose_landmarks_style()\n",
    "custom_connections = list(mp_pose.POSE_CONNECTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "b45ece64-6d87-4bde-8f32-7b32ad045947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "b3809e77-805b-4647-b4e7-07751a6a745b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom_connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "a86d14b2-48d5-430d-afe1-949c4441b0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded_landmarks = [\n",
    "    PoseLandmark.LEFT_EYE_INNER, \n",
    "    PoseLandmark.LEFT_EYE_OUTER, \n",
    "    PoseLandmark.LEFT_EAR, \n",
    "    PoseLandmark.LEFT_PINKY,\n",
    "    PoseLandmark.LEFT_EAR,\n",
    "    PoseLandmark.LEFT_PINKY,\n",
    "    PoseLandmark.LEFT_INDEX,\n",
    "    PoseLandmark.LEFT_THUMB,\n",
    "    PoseLandmark.LEFT_FOOT_INDEX,\n",
    "    PoseLandmark.RIGHT_EYE_INNER, \n",
    "    PoseLandmark.RIGHT_EYE_OUTER, \n",
    "    PoseLandmark.RIGHT_EAR, \n",
    "    PoseLandmark.RIGHT_PINKY,\n",
    "    PoseLandmark.RIGHT_EAR,\n",
    "    PoseLandmark.RIGHT_PINKY,\n",
    "    PoseLandmark.RIGHT_INDEX,\n",
    "    PoseLandmark.RIGHT_THUMB,\n",
    "    PoseLandmark.RIGHT_FOOT_INDEX,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "8ba03451-33ce-4130-a53f-6b627a8c41be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(excluded_landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "id": "fce9a18a-ec8e-4509-8644-8b69842b3c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for landmark in excluded_landmarks:\n",
    "    # we change the way the excluded landmarks are drawn\n",
    "    custom_style[landmark] = DrawingSpec(color=(255,0,0), thickness=None, circle_radius=2)\n",
    "    # we remove all connections which contain these landmarks\n",
    "    custom_connections = [connection_tuple for connection_tuple in custom_connections \n",
    "                            if landmark.value not in connection_tuple]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "d91cb335-a8bc-4ea3-9bc2-d459bd0b2eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "fe89c76b-7cb2-43e3-a722-ff1fa87d8acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom_connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "d6911953-0261-4fbb-bd58-9a469ccaf1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1726812223.976020 3603984 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88.1), renderer: Apple M3 Pro\n",
      "W0000 00:00:1726812224.041452 3686473 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1726812224.061651 3686483 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "pose = mp_pose.Pose(model_complexity = 2, \n",
    "                    min_detection_confidence = 0.5, \n",
    "                    min_tracking_confidence = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "e76d7201-14c5-475c-aa09-cd17720080c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1726812107.500290 3685430 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1726812107.523197 3685440 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "keypoint_names = [\n",
    "    'nose',\n",
    "    'left_eye_inner', 'left_eye', 'left_eye_outer',\n",
    "    'right_eye_inner', 'right_eye', 'right_eye_outer',\n",
    "    'left_ear', 'right_ear',\n",
    "    'mouth_left', 'mouth_right',\n",
    "    'left_shoulder', 'right_shoulder',\n",
    "    'left_elbow', 'right_elbow',\n",
    "    'left_wrist', 'right_wrist',\n",
    "    'left_pinky', 'right_pinky',\n",
    "    'left_index', 'right_index',\n",
    "    'left_thumb', 'right_thumb',\n",
    "    'left_hip', 'right_hip',\n",
    "    'left_knee', 'right_knee',\n",
    "    'left_ankle', 'right_ankle',\n",
    "    'left_heel', 'right_heel',\n",
    "    'left_foot_index','right_foot_index',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "1f739d71-380a-48ec-8ba8-2186e05094a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoint_names_orientation = [\n",
    "    'nose',\n",
    "    'left_eye', 'right_eye',\n",
    "    'left_shoulder', 'right_shoulder'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "f39c3e91-b43f-4d7e-8654-7865e9232e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoint_names_body = [\n",
    "    'nose',\n",
    "    'left_eye', 'right_eye',\n",
    "    'left_shoulder', 'right_shoulder',\n",
    "    'left_elbow', 'right_elbow',\n",
    "    'left_wrist', 'right_wrist',\n",
    "    'left_hip', 'right_hip',\n",
    "    'left_knee', 'right_knee',\n",
    "    'left_ankle', 'right_ankle',\n",
    "    'left_heel', 'right_heel',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "e6fc77be-92a8-4970-9d50-d3d9c3b9194b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_video(fname_video_in=None, fname_video_out=None, fps_out=10):\n",
    "\n",
    "    video_in = cv2.VideoCapture(fname_video_in)\n",
    "\n",
    "    fps_in = int( np.round( video_in.get( cv2.CAP_PROP_FPS ) ) )\n",
    "    skip   = int( fps_in/fps_out )\n",
    "\n",
    "    w_frame = int(video_in.get(3)) \n",
    "    h_frame = int(video_in.get(4))\n",
    "    size = (w_frame, h_frame)    \n",
    "    \n",
    "    num_frames = int(video_in.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    print('Reading video data from {}...\\n(frame_w, frame_h) = {}; num_frames: {}\\n********'.format(\n",
    "        fname_video_in, size, num_frames))\n",
    "\n",
    "    video_out = cv2.VideoWriter(fname_video_out, \n",
    "                                cv2.VideoWriter_fourcc(*'mp4v'), \n",
    "                                fps_out, \n",
    "                                size)\n",
    "\n",
    "    print('Processing video...')\n",
    "    fnum2landmarks = {}\n",
    "    for fnum in tqdm( range(num_frames) ):\n",
    "    \n",
    "        ret, frame = video_in.read()\n",
    "\n",
    "        if ret:\n",
    "            if fnum % skip == 0:\n",
    "\n",
    "                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                # pass frame by reference for optimization\n",
    "                frame_rgb.flags.writeable = False\n",
    "                results = pose.process(frame_rgb)\n",
    "\n",
    "                # only measure landmarks if detected\n",
    "                if results.pose_landmarks is not None:\n",
    "                \n",
    "                    landmarks = {}\n",
    "                    for i, lm in enumerate( results.pose_landmarks.landmark ):\n",
    "                        if keypoint_names[i] in keypoint_names_orientation:\n",
    "                            landmarks[keypoint_names[i]] = np.asarray( [ int(w*lm.x), int(h*lm.y) ] )\n",
    "                    fnum2landmarks[fnum] = landmarks\n",
    "\n",
    "                    # make frame writeable for drawing\n",
    "                    frame_rgb.flags.writeable = True\n",
    "                    mp_drawing.draw_landmarks(\n",
    "                        frame_rgb,\n",
    "                        landmark_list= results.pose_landmarks,\n",
    "                        # # defaults\n",
    "                        # mp_pose.POSE_CONNECTIONS,\n",
    "                        # landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style()\n",
    "                        connections = custom_connections, #  passing the modified connections list\n",
    "                        landmark_drawing_spec = custom_style, # and drawing style\n",
    "                    )\n",
    "\n",
    "                # write out to output video file\n",
    "                video_out.write( cv2.cvtColor( frame_rgb, cv2.COLOR_RGB2BGR) )\n",
    "\n",
    "        # break out of loop if end of video has been reached\n",
    "        else:\n",
    "            print('Saving results to {}'.format(fname_video_out))\n",
    "            break\n",
    "    \n",
    "    # release handles\n",
    "    video_in.release() \n",
    "    video_out.release() \n",
    "    \n",
    "    return fnum2landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "id": "57dc2149-3766-499f-85fc-4a512b743592",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_video_in  = './raw_videos/video_id1.mp4'\n",
    "fname_video_out = './processed_videos/video_id1.mp4'\n",
    "fps_out = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "9ef85de8-a861-4d0a-8b24-8f7263fb4935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading video data from ./raw_videos/video_id1.mp4...\n",
      "(frame_w, frame_h) = (1920, 1080); num_frames: 2401\n",
      "********\n",
      "Processing video...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                          | 0/2401 [00:00<?, ?it/s]/Users/patricktinsley/miniconda3/envs/interim_analysis/lib/python3.9/site-packages/google/protobuf/symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  <script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_github_file-attachment-element_dist_index_js-node_modules_primer_view-co-278f98-614627bd58c2.js\"></script>\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2401/2401 [01:15<00:00, 31.94it/s]\n"
     ]
    }
   ],
   "source": [
    "fnum2landmarks = handle_video(fname_video_in=fname_video_in,\n",
    "                              fname_video_out=fname_video_out,\n",
    "                              fps_out=fps_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a392b91-94de-423b-8985-c349ccee66a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "507c36b6-a22b-40c5-93e6-45c31178e9a0",
   "metadata": {},
   "source": [
    "## Calculate Orientation of Baby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "22579c3b-08da-412b-81e4-4407d07881d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_order(eyes, nose, shoulders, axis=0):\n",
    "    order = {'E': eyes, 'N': nose, 'S': shoulders}\n",
    "    order_sortByAxis = {k: v for k, v in sorted(order.items(), key=lambda item: item[1][axis])}        \n",
    "    return '{}_{}'.format(''.join(list(order_sortByAxis.keys())), axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "ba166cba-7737-41c9-8f0a-dca87ec5b7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_orientation(fnum2landmarks):\n",
    "\n",
    "    order_votes_x = []\n",
    "    order_votes_y = []\n",
    "    \n",
    "    for fnum, landmarks in fnum2landmarks.items():\n",
    "    \n",
    "        ([nose_x, nose_y], \n",
    "         [left_eye_x, left_eye_y], \n",
    "         [right_eye_x, right_eye_y], \n",
    "         [left_shoulder_x, left_shoulder_y], \n",
    "         [right_shoulder_x, right_shoulder_y]) = landmarks.values()\n",
    "    \n",
    "        nose = [ nose_x, nose_y ]\n",
    "        eyes = [ (left_eye_x+right_eye_x)/2 , (left_eye_y+right_eye_y)/2 ]\n",
    "        shoulders = [ (left_shoulder_x+right_shoulder_x)/2 , (left_shoulder_y+right_shoulder_y)/2 ]\n",
    "    \n",
    "        order_votes_x.append( get_order(eyes, nose, shoulders, axis=0) )\n",
    "        order_votes_y.append( get_order(eyes, nose, shoulders, axis=1) )\n",
    "    \n",
    "    order_votes = order_votes_x + order_votes_y\n",
    "\n",
    "    # print(pd.Series(order_votes).value_counts())\n",
    "    \n",
    "    dominant_order = pd.Series(order_votes).value_counts().index[0]\n",
    "    \n",
    "    order2orientation = {\n",
    "        'ENS_1': 'Up',\n",
    "        'SNE_1': 'Down',\n",
    "        'ENS_0': 'Left',\n",
    "        'SNE_0': 'Right',\n",
    "    }\n",
    "    \n",
    "    return order2orientation[dominant_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "ec345f82-cd5e-4dcc-80c3-052a76382f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "orientation = get_orientation(fnum2landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "8b181991-1367-4c73-aa52-4eae92ff6cb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Left'"
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orientation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c43e030-7680-469c-b7a5-7d235fc7b497",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbfe077-87a4-48d5-a008-120c52d012ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecda45b9-a51c-46c9-8b2a-a77579e713db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta = pd.read_csv('./list_of_subjects_726_withFNAMES.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3428ce89-17ac-4dbe-9b36-4e44bc599e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10eabee9-35c2-48ea-a28b-f3367298d4bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9498b5c-7eb2-43a3-acbb-47d3d8989381",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_data = df_meta.iloc[-1]['fname_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56101500-f874-4ff7-8592-dd161193b627",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d87986-f0f8-40fe-9378-6d2f5ecef3f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8c3bd0-9ac4-46aa-97f3-613fc6b0663a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.read_csv( fname_data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2d2ff8-81ce-46ed-a735-3c0e78cbf26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fb2d68-a123-48a4-83c2-edff7e453321",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1290eb2c-564e-420e-b2db-d4ee1b3dea21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
